## 3.3. Backend development

#### 3.3.1. Overview

Backend is a significant part of the project development. It is responsible for the most of the business logic, data storage and client-server communication.

Mainly responsibilities of the backend could be divided into these parts: API, Database, Authentication and Authorization, and courses management (exporting, fetching, processing and updating).

API is the integral part of the backend. It manages the client-server communication and provides the data to the client. It also handles the authentication and authorization of the client.

Database primarily stores the users data, courses data and the personalized preferences of the users such as the courses they have taken, the courses they are interested in, etc.

Courses management includes the methods for exporting and processing courses on the platform.

#### 3.3.2. Authorization and Authentication

The backend should provide the authentication and authorization for the users. The authentication is the process of verifying the identity of the user. The authorization is the process of verifying the permissions of the user.

This crucial part allows the users to access the platform with their personalized data and preferences. It also allows the platform to provide the personalized data to the users.

Currently, Publear provides the auth with the Google Sign-In. The users can sign in with their Google account to access the platform.

This auth method provides the secure and easy way to identify the user. The mechanism's workflow is the following:

1. The user signs in with their Google account on the client side (mobile application) using GoogleAuth iOS framework.
2. Client sends the user's Google account data to the backend - temporary user token and some client identification data such as device id, client id, etc.
3. Backend verifies the user's Google account data with the Google API.
4. If the verification is passed, the backend creates new user or authenticates the existing user and provides the user token. It is afterwards used for the client-server communication as session identifier.
5. This session is obtained by the client, stored locally and used for the further requests to the backend for the personal data retrieving.

Backend also uses the session token generation method independent from the auth method. This approach allows the platform to easily add new auth methods in the future, such as YandexID, VkID, FacebookID, etc.

Another common auth method is the email and password auth. It is used for the users who do not want to use the Google Sign-In. This method is also planned to be implemented in the future. The key difference of this method is that the user data verification must be done by the backend, not by the third-party service. This makes the process more complex because of the additional email sending and verification services.

#### 3.3.3. Courses management

Courses management is the fundamental component of the platform. To describe the mechanism deeply, it is better to divide it into the following parts: courses exporting, data loading, processing and uploading.

Courses exporting is an essential part of the courses flow. It is responsible for the extracting the courses data and content from the Notion database. The mechanism of One Link Export was developed completely from scratch. The idea is to parse data and content using the least amount of work done by the course creator. This became possible by using the Notion templates for different courses, additional detailed description of the course structure and the course creation process for users and a workflows established on the backend.

The workflow consists of the following steps: retrieving course structure and metadata (such as course creator, title, overview, and available languages), parsing the contents and saving data in appropriate format on the backend for its further usage through the Publear API, and finally, additional processing, including media loading and saving, data validation, and content parsing. After all the steps are completed successfully, the course is ready for the publication - on this stage is become available for all the users on the platform.

Since the courses validation is a crucial part, it is now done manually by the Publear team. Hence two uploading stages exist - moderation and final uploading. Uploading a course for moderation triggers all the steps described above, except the publishing course to the platform with public access. However this course still could be accessed by the author to check the correctness and by the Publear moderation team to verify and approve the course for publication.

To make the platform content more flexible, courses contain some metadata such as target action for the course, course type (minicourse or full course), and the course available language. Depending on this criteria, the platform UI is adjusted to lead the user to the most relevant content. For example, target action might be a 'course uploading' in course with description of new courses creation workflow, of 'try practice' in the courses with practices for users who had never tried this functionality before. In future, such flexibility combined with logging and A/B testing will allow the development team to increase the release speed of new features and improve the user experience faster.

#### 3.3.3. Client-Server communication and API

The communication between client (application) and server (backend via API) is a crucial part of any application. This enables the client to get external data, perform resources consuming operations on the server side, store and retrieve data.

Publear API provides number of endpoints for the client to interact with the platform. They are divided into different API routers: `auth`, `account`, and `dataitems`. Each router is responsible for the specific part of the functionality. Auth router provides the described above authorization and authentication methods. Account router is responsible for the user's personal preferences and data retrieving, such as profile picture, user's courses, likes, subscriptions, etc. Dataitems router is responsible for the courses data retrieving and processing - e.g. obtaining courses list, course metadata and content, practices, etc.

There are several common and expected problems in such approach. First is the API and client app versioning. This imposes some restrictions on the updating workflow. New application or API version cannot be established without nessessary changes in the other part. This also requires the server to support different versions of API to ensure that clients with older versions of the app will still be able to use the platform.

Another problem is the data consistency and integrity. The data should be consistent and valid on the client and server side. This requires the additional validation and verification of the data on the server side and additional requests to the server to ensure the data is up to date, however this is also a challenging task in case of slow connection or the absence of the Internet on device. To solve this problem, Publear uses the excessive data storing approach. Every change in the data is firstly safely stored in the local device storage to ensure the data will not be lost in the future. At the same time, client is performing the request to the API to update (add, delete or modify) the data in the database. Only after the successful response we can be sure that the data is consistent and on the other application launch we should trust the data from the cloud. Otherwise, the client should continue to use the local copy of the data until the connection is restored and try to update the data whenever it is possible. There is no doubt that this approach is not perfect and requires additional work and double checking, but it is quite reliable and simply to implement, thus it is used in the Publear platform for now.
